{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6b341b9-4649-46ac-9f6c-6d8bdd126170",
   "metadata": {},
   "source": [
    "# Power Infrastructure\n",
    "\n",
    "In this notebook, we will perform a **damage and risk assessment** for power infrastructure. The assessment is based on combining hazard data (e.g., flood depths) with vulnerability curves to estimate the potential damage to infrastructure.\n",
    "\n",
    "We will follow the steps outlined below to conduct the assessment:\n",
    "\n",
    "1. **Loading the necessary packages:**  \n",
    "   We will import the Python libraries required for data handling, analysis, and visualization.\n",
    "\n",
    "2. **Loading the data:**  \n",
    "   The infrastructure data (e.g., substations) and hazard data (e.g., flood depths) will be loaded into the notebook.\n",
    "\n",
    "3. **Preparing the data:**  \n",
    "   The infrastructure and hazard data will be processed and data gaps can be filled, if required.\n",
    "\n",
    "4. **Performing the damage assessment:**  \n",
    "   We will apply vulnerability curves to estimate the potential damage based on the intensity of the hazard.\n",
    "\n",
    "5. **Visualizing the results:**  \n",
    "   Finally, we will visualize the estimated damage using graphs and maps to illustrate the impact on healthcare infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a1efb4-69d5-4558-907f-d2e49ad7f9e8",
   "metadata": {},
   "source": [
    "## 1. Loading the Necessary Packages\n",
    "To perform the assessment, we are going to make use of several [python packages](https://docs.python.org/3/tutorial/modules.html#packages).\n",
    "\n",
    "In case you run this in Google Colab, you will have to install the packages below **(remove the hashtag in front of them)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c6ae5d-1f1c-4fbf-ba7f-8c63026f34dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install damagescanner==0.9b10\n",
    "#!pip install contextily\n",
    "#!pip install exactextract\n",
    "#!pip install osm-flex\n",
    "#!pip install lonboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d678797c-9d70-4641-8248-e3601d30ad1c",
   "metadata": {},
   "source": [
    "In this step, we will import all the required Python libraries for data manipulation, spatial analysis, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aaf0f4-aef2-4a67-9c30-c68f8f6550b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import rasterio\n",
    "import shapely\n",
    "import traceback\n",
    "import warnings\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray\n",
    "import contextily as cx\n",
    "\n",
    "import damagescanner.download as download\n",
    "from exactextract import exact_extract\n",
    "from damagescanner.core import DamageScanner\n",
    "from damagescanner.osm import read_osm_data\n",
    "from lonboard import viz\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning) # exactextract gives an error that is invalid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5221d308-3de6-4809-912a-3380f8689b44",
   "metadata": {},
   "source": [
    "### Specify the country of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb24ca2-dfac-4e29-9280-6029cd46674b",
   "metadata": {},
   "source": [
    "Before we continue, we should specify the country for which we want to assess the damage. We use the ISO3 code for the country to download the OpenStreetMap data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684bae52-154c-44e1-9439-b38be147ea5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_full_name = 'Vietnam'\n",
    "country_iso3 = 'VNM'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43578d8-ea9d-48e9-80b3-aa3bc0f99af7",
   "metadata": {},
   "source": [
    "## 2. Loading the Data\n",
    "In this step, we will load four key datasets:\n",
    "\n",
    "1. **Infrastructure data:**  \n",
    "   This dataset contains information on the location and type of transportation infrastructure (e.g., roads). Each asset may have attributes such as type, length, and replacement cost.\n",
    "\n",
    "2. **Hazard data:**  \n",
    "   This dataset includes information on the hazard affecting the infrastructure (e.g., flood depth at various locations).\n",
    "\n",
    "3. **Vulnerability curves:**  \n",
    "   Vulnerability curves define how the infrastructure's damage increases with the intensity of the hazard. For example, flood depth-damage curves specify how much damage occurs for different flood depths.\n",
    "\n",
    "4. **Maximum damage values:**  \n",
    "   This dataset contains the maximum possible damage (in monetary terms) that can be incurred by individual infrastructure assets. This is crucial for calculating total damage based on the vulnerability curves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca4b6a6-8558-4caf-a170-741a38f0ed56",
   "metadata": {},
   "source": [
    "### Infrastructure Data\n",
    "\n",
    "We will perform this example analysis for Jamaica. To start the analysis, we first download the OpenStreetMap data from GeoFabrik. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91971e0c-f5bd-41cc-90c8-866ccbe589d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "infrastructure_path = download.get_country_geofabrik(country_iso3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed16ff7-a9b4-4793-990d-eecc2e842ced",
   "metadata": {},
   "source": [
    "Now we load the data and read only the healthcare data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dfb1ee-4b1b-481a-b0a2-9a615bdde8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "features = read_osm_data(infrastructure_path,asset_type='power')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aad40b-658a-42ba-9838-e4c0f24fd1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_types = features.object_type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a63ad14-a317-4228-b781-7074e82b6c08",
   "metadata": {},
   "source": [
    "And we can explore our data interactively "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8746d133-185e-4537-b6f6-5c4c5a25510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d89865b-030d-4be4-a6ef-ce18b05716ee",
   "metadata": {},
   "source": [
    "### Hazard Data\n",
    "For this example, we make use of the flood data provided by [CDRI](https://giri.unepgrid.ch/map?list=explore).\n",
    "\n",
    "We use a 1/100 flood map to showcase the approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caae035e-64f2-4c69-9565-e95f73fe067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazard_map = xr.open_dataset(\"https://hazards-data.unepgrid.ch/global_pc_h100glob.tif\", engine=\"rasterio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f25659-8d72-4826-9b69-f0ee1d7e373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazard_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee05bef0-90c3-4f33-814f-fb421246e1be",
   "metadata": {},
   "source": [
    "### Maximum damages\n",
    "One of the most difficult parts of the assessment is to define the maximum reconstruction cost of particular assets. Here we provide a baseline set of values, but these should be updated through national consultations.\n",
    "\n",
    "Locations of substations (or power plants) are (somewhat randomly) geotagged as either points or polygons. This matters quite a lot for the maximum damages. For polygons, we would use damage per square meter, whereas for points, we would estimate the damage to the entire asset at once. Here we take the approach of converting the points to polygons, and there define our maximum damages in dollar per square meter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df3cdf-4f61-470f-8b7e-c1eb6d01bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxdam_dict = {\n",
    "    'tower': 1000, \n",
    "    'pole': 1000, \n",
    "    'portal': 1000, \n",
    "    'switch': 1000, \n",
    "    'cable': 1000, \n",
    "    'generator': 1000, \n",
    "    'transformer': 1000, \n",
    "    'plant': 1000, \n",
    "    'substation': 1000,  \n",
    "    'line': 1000, \n",
    "    'minor_line': 1000, \n",
    "     }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79192a0b-8615-432e-b55b-63df78629924",
   "metadata": {},
   "source": [
    "To be used in our damage assessment, we convert this to a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd0aeec-16eb-4ef6-afcf-9cbc7372a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxdam = pd.DataFrame.from_dict(maxdam_dict,orient='index').reset_index()\n",
    "maxdam.columns = ['object_type','damage']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b69fd7-393a-48f6-aae6-33b19bb2e3b9",
   "metadata": {},
   "source": [
    "### Vulnerability data\n",
    "Similarly to the maximum damages, specifying the vulnerability curves is complex. We generally have limited information about the quality of the assets, its level of deteriation and other asset-level characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8a021f-0c9d-41a7-846b-fd78af69cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "vulnerability_path = \"https://zenodo.org/records/10203846/files/Table_D2_Multi-Hazard_Fragility_and_Vulnerability_Curves_V1.0.0.xlsx?download=1\"\n",
    "vul_df = pd.read_excel(vulnerability_path,sheet_name='F_Vuln_Depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad555da-f453-4e2a-9d7b-dcb20e6e960b",
   "metadata": {},
   "source": [
    "And let's have a look at all the available options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a14865-3350-41ba-ad48-eb4886c63874",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None):\n",
    "  display(vul_df.iloc[:2,:].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393085ef-cdab-4e9f-b1d3-6a2c478a5e1b",
   "metadata": {},
   "source": [
    "And select a curve to use for each different subtype we are analysing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f857b2ac-1714-4127-a834-4091af1e82c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_curves = dict(zip(sub_types,['F10.1','F2.3','F6.1','F2.2','F6.1','F1.2','F2.2','F2.2','F2.1','F6.1','F6.1','F6.1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b1bbd3-3316-4345-85ac-87c262eb5a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f55ae20-29c7-457b-b1dc-8adc04ecb188",
   "metadata": {},
   "outputs": [],
   "source": [
    "damage_curves = vul_df[['ID number']+list(selected_curves.values())]\n",
    "damage_curves = damage_curves.iloc[4:125,:]\n",
    "damage_curves.set_index('ID number',inplace=True)\n",
    "damage_curves.index = damage_curves.index.rename('Depth')  \n",
    "damage_curves = damage_curves.astype(np.float32)\n",
    "damage_curves.columns = sub_types\n",
    "damage_curves = damage_curves.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b4648f-e3ba-4ac4-a238-ab3a5deaf108",
   "metadata": {},
   "source": [
    "Make sure we set the index of the damage curves (the inundation depth) in the same metric as the hazard data (e.g. meters or centimeters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950d28ee-cd35-4031-b994-02542cbf30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "damage_curves.index = damage_curves.index*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8f6aed-6096-4701-93b3-e2f861cd733d",
   "metadata": {},
   "source": [
    "### Ancilliary data for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef02d9a2-1790-4632-b66f-3e7e57eb9d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "world = gpd.read_file(\"https://github.com/nvkelso/natural-earth-vector/raw/master/10m_cultural/ne_10m_admin_0_countries.shp\")\n",
    "world_plot = world.to_crs(3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df306b07-906b-4601-b0d8-4c0158d2aca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "admin1 = gpd.read_file(\"https://github.com/nvkelso/natural-earth-vector/raw/master/10m_cultural/ne_10m_admin_1_states_provinces.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e288af4e-c397-46d5-a6cd-606a01ea4ed1",
   "metadata": {},
   "source": [
    "## 3. Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc45662-dce8-4f15-a673-48a92bbd247b",
   "metadata": {},
   "source": [
    "Clip the hazard data to the country of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c53736-48af-4dd7-8443-95b1039d7653",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_bounds = world.loc[world.ADM0_ISO == country_iso3].bounds\n",
    "country_geom = world.loc[world.ADM0_ISO == country_iso3].geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cf5c27-1bfc-4b27-8b2d-790a3a478a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazard_country = hazard_map.rio.clip_box(minx=country_bounds.minx.values[0],\n",
    "                     miny=country_bounds.miny.values[0],\n",
    "                     maxx=country_bounds.maxx.values[0],\n",
    "                     maxy=country_bounds.maxy.values[0]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4725e1-53c5-4d48-b25a-c070d579e60e",
   "metadata": {},
   "source": [
    "### Convert linestring and point data to polygons. \n",
    "\n",
    "For some data, there are both points and polygons available. It makes life easier to estimate the damage using polygons. Therefore, we convert those points to Polygons below. \n",
    "\n",
    "Let's first get an overview of the different geometry types for all the assets we are considering in this analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ac6f5f-aa71-431c-9b5b-d39a546f3d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "features['geom_type'] = features.geom_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc6f845-e6d3-472f-b6d7-b2a8d7426962",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features.groupby(['object_type','geom_type']).count()['geometry']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b974a2-eff5-4ddc-aeac-5b6b495e8909",
   "metadata": {},
   "source": [
    "The results above indicate that several asset types that are expected to be *Polygons* (such as **substations** and **plants**) are stored as *LineStrings* and points. It would be preferably to convert them all to polygons. For LineStrings, we can convert them to a *Polygon*, but for the *Points*, we will have to estimate a the average size, so we can use that to create a `buffer` around the assets.\n",
    "\n",
    "Let's start with all the *LineStrings*. As we do not want to convert all LineStrings, we have to specify which assets we should \"polygonize\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fecbde2-958c-41da-b19a-60e197763af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "linestrings_to_polygonize = ['generator','plant','substation']\n",
    "\n",
    "all_assets_to_polygonize = features.loc[(features.object_type.isin(linestrings_to_polygonize)) & (features.geometry.geom_type == 'LineString')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716c1206-7225-48fb-ba0e-3ef8266b2938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygonize_linestring_per_asset(asset):\n",
    "    return shapely.Polygon(asset.geometry)\n",
    "\n",
    "collect_new_linestring_geometries = all_assets_to_polygonize.apply(lambda asset:  polygonize_linestring_per_asset(asset),axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879dc48c-4a68-4b57-a949-f911c7b3d1dc",
   "metadata": {},
   "source": [
    "Now overwrite the *LineStrings* with *Polygons*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeba18fa-6b7f-40fa-aad5-0f280691369e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features.loc[(features.object_type.isin(linestrings_to_polygonize)) & (features.geometry.geom_type == 'LineString'),'geometry'] = collect_new_linestring_geometries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40199e0c-4ad9-412a-b81e-ba29bbf37688",
   "metadata": {},
   "source": [
    "And check if any \"undesired\" *LineStrings* are still left:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6bf914-539e-4e13-a2aa-2dbac5672de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.loc[(features.object_type.isin(linestrings_to_polygonize)) & (features.geometry.geom_type == 'LineString')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40b1a5a-c142-4bb8-b85f-64bf3022a555",
   "metadata": {},
   "source": [
    "Now, the next step is to create a small buffer around the point data. We first estimate an average size of each building based on each subtype.\n",
    "\n",
    "To do so, let's grab the polygon data and estimate their size. We grab the median so we are not too much influenced by extreme outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8101e3-494c-4a75-a7cb-3ffdefe91953",
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_features = features.loc[features.geometry.geom_type.isin(['Polygon','MultiPolygon'])].to_crs(3857)\n",
    "polygon_features['square_m2'] = polygon_features.area\n",
    "\n",
    "square_m2_object_type = polygon_features[['object_type','square_m2']].groupby('object_type').median()\n",
    "square_m2_object_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625626ba-9603-4af6-a07e-5e13f2b625c0",
   "metadata": {},
   "source": [
    "Now we create, similarly to the *LineStrings*, a list in which we define the assets we want to \"polygonize\": "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0658fdba-e221-4d92-8804-f04d1f636a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_to_polygonize = ['generator','plant','substation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2874c809-9def-4352-a09d-e949e448e2ca",
   "metadata": {},
   "source": [
    "And take them from our data again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5983f8ce-981f-4a69-987d-641edb099beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_assets_to_polygonize = features.loc[(features.object_type.isin(points_to_polygonize)) & (features.geometry.geom_type == 'Point')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f09067-44f3-4016-b2bc-6682d0f6423b",
   "metadata": {},
   "source": [
    "When performing a buffer, it is always best to do this in meters. As such, we will briefly convert the point data into a **crs** system in meters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe273c7-ddc1-4394-98af-2c3f28d2387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_assets_to_polygonize = all_assets_to_polygonize.to_crs(3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93684fc7-e998-47b8-90cc-b7c3190cc37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygonize_point_per_asset(asset):\n",
    "\n",
    "    # we first need to set a buffer length. This is half of width/length of an asset.\n",
    "    buffer_length = np.sqrt(square_m2_object_type.loc[asset.object_type].values[0])/2\n",
    "\n",
    "    # then we can buffer the asset\n",
    "    return asset.geometry.buffer(buffer_length,cap_style='square')\n",
    "\n",
    "collect_new_point_geometries = all_assets_to_polygonize.apply(lambda asset:  polygonize_point_per_asset(asset),axis=1).set_crs(3857).to_crs(4326).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b8f0ca-c5ac-43e8-9813-c9353289efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.loc[(features.object_type.isin(points_to_polygonize)) & (features.geometry.geom_type == 'Point'),'geometry'] = collect_new_point_geometries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8039db-bb04-4945-9d0a-e9c04c51e9e1",
   "metadata": {},
   "source": [
    "And check if any \"undesired\" *Points* are still left:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563b6a74-cf14-41f4-95fe-918ce283d96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.loc[(features.object_type.isin(points_to_polygonize)) & (features.geometry.geom_type == 'Point')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6c67ce-260e-44c3-ae85-734f83850dd7",
   "metadata": {},
   "source": [
    "And remove the 'geom_type' column again, as we do not need it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ffe040-d06d-41ba-b4bd-8f2722f68093",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.drop(['geom_type'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce0650d-68a9-427a-9602-e318989dec00",
   "metadata": {},
   "source": [
    "## 5. Performing the Damage Assessment\n",
    "We will use the DamageScanner approach. This is a fully optimised damage calculation method, that can capture a wide range of inputs to perform a damage assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b13e5d7-1cfe-4bb2-b169-51f4e14c5398",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "damage_results = DamageScanner(hazard_country, features, damage_curves, maxdam).calculate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2d88c1-e5e5-4bc3-a0fb-1e4e99c4789d",
   "metadata": {},
   "source": [
    "## 5. Save the Results\n",
    "For further analysis, we can save the results in their full detail, or save summary estimates per subnational unit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95461586-56ff-48c7-b959-eb3b364500fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hazard = 'river_flood'\n",
    "return_period = '1_100'\n",
    "damage_results.to_csv(f'Power_Damage_{country_full_name}_{hazard}_{return_period}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba6148f-4e6e-486c-821b-0635a94d4955",
   "metadata": {},
   "outputs": [],
   "source": [
    "admin1_country = admin1.loc[admin1.sov_a3 == country_iso3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a4437-fb9e-46ea-8ec2-218f81fee90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "damage_results = damage_results.sjoin(admin1_country[['adm1_code','name','geometry']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c934bcb0-1bd5-4b6b-8d74-3de9e49ce16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "admin1_damage = admin1_country.merge(damage_results[['name_right','damage']].groupby('name_right').sum(),\n",
    "                                     left_on='name',\n",
    "                                     right_on='name_right',\n",
    "                                     how='outer')[['name','adm1_code','geometry','damage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8f1db1-ba5e-4ed7-ba8b-6f6ad089b15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "admin1_damage.to_csv(f'Admin1_Power_Damage_{country_full_name}_{hazard}_{return_period}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d64f90d-bf96-47af-bcc2-c360a488cb65",
   "metadata": {},
   "source": [
    "## 6. Visualizing the Results\n",
    "The results of the damage assessment can be visualized using charts and maps. This will provide a clear representation of which infrastructure is most affected by the hazard and the expected damage levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22ad4ae-c7b4-480e-8286-3328bb182ee7",
   "metadata": {},
   "source": [
    "And create a distribution of the damages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c60f11f-ab90-4342-a17e-cbc082cdbd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(7, 3))\n",
    "\n",
    "sns.histplot(data=damage_results,x='damage',ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a66d7e-6cb8-4cf1-aa79-90df85ae6991",
   "metadata": {},
   "source": [
    "Plot location of most damaged healthcare facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e16e6e2-ec0b-4218-b550-43ed39dd2a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(10, 5))\n",
    "\n",
    "subset = damage_results.to_crs(3857).sort_values('damage',ascending=False).head(20)\n",
    "subset.geometry = subset.centroid\n",
    "subset.plot(ax=ax,column='object_type',markersize=10,legend=True)\n",
    "world_plot.loc[world.SOV_A3 == country_iso3].plot(ax=ax,facecolor=\"none\",edgecolor='black')\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron,alpha=0.5)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa71033a-a9e3-4d4d-ba02-2fae5ba0f11d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
